{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "iiNx2Tr34rJy",
        "outputId": "075bc898-fe54-4f67-b895-2ea6c7a17c35"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Original Data:\n",
            "    feature1  feature2  feature3\n",
            "0         1        10       100\n",
            "1         2        15       150\n",
            "2         3        20       200\n",
            "3         4        25       250\n",
            "4         5        30       300\n",
            "\n",
            "Standardized Data:\n",
            "    feature1  feature2  feature3\n",
            "0 -1.414214 -1.414214 -1.414214\n",
            "1 -0.707107 -0.707107 -0.707107\n",
            "2  0.000000  0.000000  0.000000\n",
            "3  0.707107  0.707107  0.707107\n",
            "4  1.414214  1.414214  1.414214\n"
          ]
        }
      ],
      "source": [
        "from sklearn.preprocessing import StandardScaler\n",
        "import pandas as pd\n",
        "\n",
        "# Sample data\n",
        "data = {\n",
        "    'feature1': [1, 2, 3, 4, 5],\n",
        "    'feature2': [10, 15, 20, 25, 30],\n",
        "    'feature3': [100, 150, 200, 250, 300]\n",
        "}\n",
        "df = pd.DataFrame(data)\n",
        "\n",
        "# Initialize the StandardScaler\n",
        "scaler = StandardScaler()\n",
        "\n",
        "# Fit and transform the data\n",
        "standardized_data = scaler.fit_transform(df)\n",
        "\n",
        "# Convert the standardized data back to a DataFrame\n",
        "standardized_df = pd.DataFrame(standardized_data, columns=df.columns)\n",
        "\n",
        "print(\"Original Data:\\n\", df)\n",
        "print(\"\\nStandardized Data:\\n\", standardized_df)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **Explanation:**\n",
        "# StandardScaler: Calculates the mean and standard deviation for each feature and uses them to scale the data.\n",
        "# fit_transform: Fits the scaler on the data and transforms it simultaneously.\n",
        "# Output: Displays the original and standardized data.\n",
        "The standardized DataFrame will have a mean of 0 and a standard deviation of 1 for each feature. This technique is especially useful when applying algorithms that are sensitive to feature scaling, like K-means clustering and principal component analysis (PCA)."
      ],
      "metadata": {
        "id": "k88MyVZ_4uPr"
      }
    }
  ]
}